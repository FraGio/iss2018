Fatte le git pull sulle due repository, poi agiornata la libreria qa18akka.jar.
Il prof apre un hotspot con il telefono, chiamato NAT.
L'executor e il radar sono due entità mappate su IP differenti (nel virtualRobotExecutor.qa del prof).
Facciamo partire il radar in locale.
Il codice inteso come modello cattura solo gli aspetti essenziali, per cui riesco a tenere documentato il codice.
Cosa fa il virtualRobotExecutor (nel progetto "it.unibo.mbot.divide")? Da notare che è mbotExecutor.qa rinominato, quindi lo abbiamo già nel progetto precedente.
Nelle rules c'è un fatto Prolog (finisce con .), che è unityConfig.
Cos'è tecnicamente "Plan waitForCmd"? E' la specifica di uno stato del QActorRover, che è modellato come automa a stati finiti.
Cosa fa tecnicamente l'automa in questo stato? Nulla, perchè è modellato come automa a stati finiti di Moore. C'è l'attesa di un messaggio, che deve chiamarsi "moveRover".
Chi genera il messaggio "moveRover"? Nella nostra versione lo usrcmdmanager, nella versione del prof non c'è, bensì c'è un EventHandler evh.
Cos'è un eventHandler nel nostro mondo? E' un entità che lavora nel contesto, e lavora in modo event driven rispetto ad eventi usercmd o mindcmd.
Supponiamo che vengano generati mille usercmd, cosa succede? Siccome questo eventHandler lavora come event driven esso eseguirà quello presente tra parentesi graffa (body), e non verranno persi messaggi. Nel body viene trasformato un evento usercmd o mindcmd in un messagio (o meglio dispatch) moveRover.
Questo funziona solo se il payload di usercmd e mindcmd è lo stesso, e sarà lo stesso in moveRover.
Commentiamo lo usercmdmanager, dovremmo avere degli errori.
Guardiamo il Plan execMove: sostituiamo questo con il codice nuovo del prof. Non c'è più javaRun, che dava il comando sia sul fisico che sul virtuale, perchè adesso lavoriamo solo nel virtuale.
Guardiamo il waitForEvents: veniva catturato il payload di un evento sonar generato da unity.
Divide et impera se scaturisce dal problema allora è competenza dell'analista, se invece è una scelta di modularità allora è fatta dal progettista.
Ha senso commentare realSonar, cioè il sonar del mondo reale, perchè stiamo lavorando solo nel virtuale? Il robot virtuale potrebbe, in un secondo momento, voler ricevere informazioni dal mondo reale, anche se al momento siamo interessati solo al mondo virtuale.
Non sappiamo se i nostri componenti funzionano o meno, quindi bisogna passare a una fase di testing. Il primo testing è sicuramente quello di lanciare l'executor (da src-gen).
Non va più niente, ma dopo copia incolla da virtualRobotExecutor a mbotExecutor funziona.

Il logger, in fase prototipale, deve fare logging inizialmente in console, ma in seguito su memoria persistente.
A cosa deve pensare l'analista: tutti gli eventi o solo quelli importanti?
Quali sono le problematiche che l'analista può far venire fuori?
Il logger può essere introdotto dentro l'mbotExecutor, come nuovo QActor, oppure come entità separata.
E' opportuno mettere un logger all'interno di un componente già esistente?
Come fa quell'entità a intercettare tutti gli eventi generati nel sistema?
Nell'mbotExecutor c'è un mindcmd, che non è specificato da altre parti.
Abbiamo già l'event logger grazie all'EventHandler esistente, ma se vengono aggiunti nuovi eventi emessi nel mio sistema che voglio loggare non li ho.
Se volessi catturare i "polar" oltre a usercmd e mindcmd? Non posso semplicemente aggiungerlo all'attuale EventHandler, perchè il payload è differente. Dovrei per cui creare un nuovo EventHandler, ma in questo modo perderei sequenzialità degli eventi.
E se volessimo catturare altri eventi? Non possiamo continuare a lavorare sull'mbotExecutor, non è il suo compito quello di fare logging. Quindi il rischio è di scrivere codice che poi buttiamo via.
Dovrò prevedere una nuova entità che genera comandi mindcmd, chiamato agent, che avrà un progetto nuovo e un modello nuovo. In questo modello verranno generati mindcmd.
Il nuovo componente deve essere singolo ma non deve essere standalone, deve collegarsi ad uno dei due contesti che abbiamo a nostra disposizione (mbotExecutor o radar).
Cosa succede dal punto di vista logico quando il contesto che supporta il nostro sistema comincia a girare (es. mbotExecutor necessita del radar)?
Il radar ha conoscenza solo di sè stesso, funziona ed esegue. Il mbotExecutor conosce il radar e necessita del radar per funzionare, quindi deve attaccarsi al radar (solo se esso è partito) e, in seguito a questo, l'infrastruttura degli attori (QActor) renderà noto al radar che non è più singolo ma è associato al mbotExecutor.
Cosa succede se il radar si scollega? Bisognerebbe fare fault tolerance, cioè l'infrastruttura dovrebbe rendere noto al radar che è tornato entità singola del sistema e tutto dovrebbe iniziare come nella situazione iniziale (idempotenza).
Cosa fa l'entità mind? Si collega al radar, quindi in questo caso l'infrastruttura rende noto al radar che fa parte di questo nuovo sistema di due entità. In realtà l'infrastruttura dovrebbe rendere noto alle tre entità in gioco che ora sono tutte interconnesse e fanno parte dello stesso sistema.
L'aspettativa della mind quando emette il mindcmd è che l'evento venga propagato automaticamente dall'infrastruttura a tutti i componenti del sistema.
L'infrastruttura ha quindi una forte conoscenza del sistema software, a fronte di un "semplice" flag "-standalone".
Se l'mbotExecutor emette polar la mind può ricevere l'evento? Sì, perchè adesso tutte le entità fanno parte dello stesso sistema.

Possiamo usare un mqtt server, in modo che ci siano emettitori e ricevitori e che gli eventi non vengano persi.
La strategia è scrivere tutto basandosi sui QActor, poi non devo cambiare il codice di una virgola se voglio cambiare l'infrastruttura sotto e passare a quella a scambio di messaggi.

Chi si muove quando la mind emette il mindcmd che muove il robot? Tutti i robot che sono in grado di ricevere il comando ed interpretarlo correttamente.
Cosa fa il plan handle in mindOfRobot.qa (progetto "divide")? Me lo sono perso.

Il prof prova a far girare il sistema con i soliti radar, mbotExecutor e unity. Il virtual bot non si ferma quando passa davanti a un sonar virtuale, quindi ora facciamo partire il terzo componente che si chiama mindOfRobot. La mind dovrebbe far avanzare il robot, poi in corrispondenza del sonar deve far scodinzolare il robot e farlo fermare.

*** guardare sezione 11 del caseStudy.pdf ***

Cosa faremmo per far girare il robot reale? Nuovo componente realRobot che deve essere attaccato al sistema, deve esere compatibile sia da mindcmd sia con usercmd.